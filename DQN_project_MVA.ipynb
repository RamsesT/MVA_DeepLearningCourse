{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DQN_project_MVA.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RamsesT/MVA_DeepLearningCourse/blob/master/DQN_project_MVA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "VPaaHfLISu9y",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**You may need to install [OpenCV](https://pypi.python.org/pypi/opencv-python) and [scikit-video](http://www.scikit-video.org/stable/).**"
      ]
    },
    {
      "metadata": {
        "id": "-sG8jLy2Pkax",
        "colab_type": "code",
        "outputId": "43bc68f2-5486-41e9-f7e0-75e20de76a0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install sk-video"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sk-video in /usr/local/lib/python3.6/dist-packages (1.1.10)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.1.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from sk-video) (1.14.6)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "isXsC0ruSu90",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import keras\n",
        "import numpy as np\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "import skvideo.io\n",
        "import cv2\n",
        "import json\n",
        "\n",
        "from keras.models import Sequential,model_from_json\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import sgd\n",
        "from keras.layers import Conv2D, MaxPooling2D, Activation, AveragePooling2D,Reshape,BatchNormalization, Flatten\n",
        "\n",
        "np.random.seed(1)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sA8jnkzESu96",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# MiniProject #3: Deep Reinforcement Learning"
      ]
    },
    {
      "metadata": {
        "id": "pRvNlb9ESu97",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Notations__: $E_p$ is the expectation under probability $p$. Please justify each of your answer and widely comment your code."
      ]
    },
    {
      "metadata": {
        "id": "NQ6egFCySu98",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Context"
      ]
    },
    {
      "metadata": {
        "id": "L58_sAESSu99",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In a reinforcement learning algorithm, we modelize each step $t$ as an action $a_t$ obtained from a state $s_t$, i.e. $\\{(a_{t},s_{t})_{t\\leq T}\\}$ having the Markov property. We consider a discount factor $\\gamma \\in [0,1]$ that ensures convergence. The goal is to find among all the policies $\\pi$, one that maximizes the expected reward:\n",
        "\n",
        "\\begin{equation*}\n",
        "R(\\pi)=\\sum_{t\\leq T}E_{p^{\\pi}}[\\gamma^t r(s_{t},a_{t})] \\> ,\n",
        "\\end{equation*}\n",
        "\n",
        "where: \n",
        "\\begin{equation*}p^{\\pi}(a_{0},a_{1},s_{1},...,a_{T},s_{T})=p(a_{0})\\prod_{t=1}^{T}\\pi(a_{t}|s_{t})p(s_{t+1}|s_{t},a_{t}) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "We note the $Q$-function:\n",
        "\n",
        "\\begin{equation*}Q^\\pi(s,a)=E_{p^{\\pi}}[\\sum_{t\\leq T}\\gamma^{t}r(s_{t},a_{t})|s_{0}=s,a_{0}=a] \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "Thus, the optimal Q function is:\n",
        "\\begin{equation*}\n",
        "Q^*(s,a)=\\max_{\\pi}Q^\\pi(s,a) \\> .\n",
        "\\end{equation*}\n",
        "\n",
        "In this project, we will apply the deep reinforcement learning techniques to a simple game: an agent will have to learn from scratch a policy that will permit it maximizing a reward."
      ]
    },
    {
      "metadata": {
        "id": "lOZHjRqOSu9-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## The environment, the agent and the game"
      ]
    },
    {
      "metadata": {
        "id": "0CLf00uDSu9_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The environment"
      ]
    },
    {
      "metadata": {
        "id": "AW6RMtknSu-A",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "```Environment``` is an abstract class that represents the states, rewards, and actions to obtain the new state."
      ]
    },
    {
      "metadata": {
        "id": "lR09UnP-Su-A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self):\n",
        "        pass\n",
        "\n",
        "    def act(self, act):\n",
        "        \"\"\"\n",
        "        One can act on the environment and obtain its reaction:\n",
        "        - the new state\n",
        "        - the reward of the new state\n",
        "        - should we continue the game?\n",
        "\n",
        "        :return: state, reward, game_over\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"\n",
        "        Reinitialize the environment to a random state and returns\n",
        "        the original state\n",
        "\n",
        "        :return: state\n",
        "        \"\"\"\n",
        "        pass\n",
        "    \n",
        "    def draw(self):\n",
        "        \"\"\"\n",
        "        Visualize in the console or graphically the current state\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OL2DOQTtSu-D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The method ```act``` allows to act on the environment at a given state $s_t$ (stored internally), via action $a_t$. The method will return the new state $s_{t+1}$, the reward $r(s_{t},a_{t})$ and determines if $t\\leq T$ (*game_over*).\n",
        "\n",
        "The method ```reset``` simply reinitializes the environment to a random state $s_0$.\n",
        "\n",
        "The method ```draw``` displays the current state $s_t$ (this is useful to check the behavior of the Agent).\n",
        "\n",
        "We modelize $s_t$ as a tensor, while $a_t$ is an integer."
      ]
    },
    {
      "metadata": {
        "id": "WTbSp7l2Su-E",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### The Agent"
      ]
    },
    {
      "metadata": {
        "id": "yq9m_NJuSu-F",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The goal of the ```Agent``` is to interact with the ```Environment``` by proposing actions $a_t$ obtained from a given state $s_t$ to attempt to maximize its __reward__ $r(s_t,a_t)$. We propose the following abstract class:"
      ]
    },
    {
      "metadata": {
        "id": "mqksiyeFSu-G",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Agent(object):\n",
        "    def __init__(self, epsilon=0.1, n_action=4):\n",
        "        self.epsilon = epsilon\n",
        "        self.n_action = n_action\n",
        "    \n",
        "    def set_epsilon(self,e):\n",
        "        self.epsilon = e\n",
        "\n",
        "    def act(self,s,train=True):\n",
        "        \"\"\" This function should return the next action to do:\n",
        "        an integer between 0 and 4 (not included) with a random exploration of epsilon\"\"\"\n",
        "        if train:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "                a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "            else:\n",
        "                a = self.learned_act(s)\n",
        "        else: # in some cases, this can improve the performance.. remove it if poor performances\n",
        "            a = self.learned_act(s)\n",
        "\n",
        "        return a\n",
        "\n",
        "    def learned_act(self,s):\n",
        "        \"\"\" Act via the policy of the agent, from a given state s\n",
        "        it proposes an action a\"\"\"\n",
        "        pass\n",
        "\n",
        "    def reinforce(self, s, n_s, a, r, game_over_):\n",
        "        \"\"\" This function is the core of the learning algorithm. \n",
        "        It takes as an input the current state s_, the next state n_s_\n",
        "        the action a_ used to move from s_ to n_s_ and the reward r_.\n",
        "        \n",
        "        Its goal is to learn a policy.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def save(self):\n",
        "        \"\"\" This function returns basic stats if applicable: the\n",
        "        loss and/or the model\"\"\"\n",
        "        pass\n",
        "\n",
        "    def load(self):\n",
        "        \"\"\" This function allows to restore a model\"\"\"\n",
        "        pass"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "2xuM3wLKSu-I",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 1__:\n",
        "Explain the function act. Why is ```epsilon``` essential?"
      ]
    },
    {
      "metadata": {
        "id": "Q_iTrdjTSu-J",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "the function **act** is used to decide what action the agent should do. If *train* is set to **True** it will use epsilon to explore its evironement. *epsilon* is the probability that the agent will follow the action based on the best policy learned so far or if it will act randomly. This exploration is important for the agent to learn new behaviours and not just focus on a small set of strategie that it has tested. \n",
        "By setting espilon to a large value we force the agent to explore. If epsilon is small it will use what it learned."
      ]
    },
    {
      "metadata": {
        "id": "2bC0Yx9zSu-L",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "### The Game"
      ]
    },
    {
      "metadata": {
        "id": "e1VTZCo4Su-M",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The ```Agent``` and the ```Environment``` work in an interlaced way as in the following (take some time to understand this code as it is the core of the project)\n",
        "\n",
        "```python\n",
        "\n",
        "epoch = 300\n",
        "env = Environment()\n",
        "agent = Agent()\n",
        "\n",
        "\n",
        "# Number of won games\n",
        "score = 0\n",
        "loss = 0\n",
        "\n",
        "\n",
        "for e in range(epoch):\n",
        "    # At each epoch, we restart to a fresh game and get the initial state\n",
        "    state = env.reset()\n",
        "    # This assumes that the games will end\n",
        "    game_over = False\n",
        "\n",
        "    win = 0\n",
        "    lose = 0\n",
        "    \n",
        "    while not game_over:\n",
        "        # The agent performs an action\n",
        "        action = agent.act(state)\n",
        "\n",
        "        # Apply an action to the environment, get the next state, the reward\n",
        "        # and if the games end\n",
        "        prev_state = state\n",
        "        state, reward, game_over = env.act(action)\n",
        "\n",
        "        # Update the counters\n",
        "        if reward > 0:\n",
        "            win = win + reward\n",
        "        if reward < 0:\n",
        "            lose = lose -reward\n",
        "\n",
        "        # Apply the reinforcement strategy\n",
        "        loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "    # Save as a mp4\n",
        "    if e % 10 == 0:\n",
        "        env.draw(e)\n",
        "\n",
        "    # Update stats\n",
        "    score += win-lose\n",
        "\n",
        "    print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "          .format(e, epoch, loss, win, lose, win-lose))\n",
        "    agent.save()\n",
        "```"
      ]
    },
    {
      "metadata": {
        "id": "G7pSDZB1Su-N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# The game, *eat cheese*"
      ]
    },
    {
      "metadata": {
        "id": "8ZRmSLS1Su-P",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "A rat runs on an island and tries to eat as much as possible. The island is subdivided into $N\\times N$ cells, in which there are cheese (+0.5) and poisonous cells (-1). The rat has a visibility of 2 cells (thus it can see $5^2$ cells). The rat is given a time $T$ to accumulate as much food as possible. It can perform 4 actions: going up, down, left, right. \n",
        "\n",
        "The goal is to code an agent to solve this task that will learn by trial and error. We propose the following environment:"
      ]
    },
    {
      "metadata": {
        "id": "4i1koNmpSu-S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Environment(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "\n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1\n",
        "        reward = self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        state = np.concatenate((self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        state = np.concatenate((\n",
        "                               self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rEKoW-hlSu-V",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The following elements are important because they correspond to the hyper parameters for this project:"
      ]
    },
    {
      "metadata": {
        "id": "KrxoaPdDSu-W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# parameters\n",
        "size = 13\n",
        "T=200\n",
        "temperature=0.3\n",
        "epochs_train=10 # set small when debugging\n",
        "epochs_test=31 # set small when debugging\n",
        "\n",
        "# display videos\n",
        "def display_videos(name):\n",
        "    video = io.open(name, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    return '''<video alt=\"test\" controls>\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oNTiK-wrSu-Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "__Question 2__ Explain the use of the arrays ```position``` and ```board```."
      ]
    },
    {
      "metadata": {
        "id": "VkSGBc_gSu-a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        " ```position``` is an array which contains the information on the position of the rat(set to 1), the places it can go (set to 0) and where he can not (the boundaries, set to -1).\n",
        "\n",
        "```board``` is an array with the poison and food positions (-1 for poison, 0.5 for food). The probability to found poison or food on a given position follows a binomial law with expectation equal to *self.temperature*\n",
        " \n",
        " Both arrays have the same shape.\n",
        " \n",
        " After each action, the rate eat what it founds in its new position. At the corresponding new position, we set the value on the board to 0 to show that there is nothing left here.\n",
        "  \n"
      ]
    },
    {
      "metadata": {
        "id": "FRiHQoYUSu-a",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Random Agent"
      ]
    },
    {
      "metadata": {
        "id": "bZ0xnnrZSu-c",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 3__ Implement a random Agent (only ```learned_act``` needs to be implemented):"
      ]
    },
    {
      "metadata": {
        "id": "5u7POkXZSu-d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class RandomAgent(Agent):\n",
        "    def __init__(self):\n",
        "        super(RandomAgent, self).__init__()\n",
        "        pass\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        a = np.random.randint(0, self.n_action, size=1)[0]\n",
        "        return a"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U0JXoPD9Su-f",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 4__ Visualize the game moves. You need to fill in the following function for the evaluation:"
      ]
    },
    {
      "metadata": {
        "id": "3Jc0b4pwSu-g",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def test(agent,env,epochs,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "        \n",
        "    for e in range(epochs):\n",
        "        \n",
        "        ##### FILL IN HERE\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will end\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            \n",
        "            action = agent.act(state, train=False) # no need to use the \"train\" feature since its a random agent\n",
        "\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "        # Save as a mp4\n",
        "        env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score = score + win-lose\n",
        "\n",
        "        print(\"Win/lose count {}/{}. Average score ({})\"\n",
        "              .format(win, lose, score/(1+e)))\n",
        "    print('Final score: '+str(score/epochs))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RABU733mSu-i",
        "colab_type": "code",
        "outputId": "062d90a6-5413-430a-ba07-75b9515337b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "cell_type": "code",
      "source": [
        "# Initialize the game\n",
        "env = Environment(grid_size=size, max_time=T,temperature=temperature)\n",
        "\n",
        "# Initialize the agent!\n",
        "agent = RandomAgent()\n",
        "\n",
        "test(agent,env,epochs_test,prefix='random')\n",
        "HTML(display_videos('random0.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 10.0/13.0. Average score (-3.0)\n",
            "Win/lose count 9.0/18.0. Average score (-6.0)\n",
            "Win/lose count 9.5/11.0. Average score (-4.5)\n",
            "Win/lose count 13.0/20.0. Average score (-5.125)\n",
            "Win/lose count 8.0/17.0. Average score (-5.9)\n",
            "Win/lose count 8.0/11.0. Average score (-5.416666666666667)\n",
            "Win/lose count 7.0/12.0. Average score (-5.357142857142857)\n",
            "Win/lose count 9.5/13.0. Average score (-5.125)\n",
            "Win/lose count 11.5/20.0. Average score (-5.5)\n",
            "Win/lose count 8.5/11.0. Average score (-5.2)\n",
            "Win/lose count 8.5/12.0. Average score (-5.045454545454546)\n",
            "Win/lose count 10.5/15.0. Average score (-5.0)\n",
            "Win/lose count 12.0/4.0. Average score (-4.0)\n",
            "Win/lose count 9.0/12.0. Average score (-3.9285714285714284)\n",
            "Win/lose count 12.5/17.0. Average score (-3.966666666666667)\n",
            "Win/lose count 6.5/15.0. Average score (-4.25)\n",
            "Win/lose count 9.5/15.0. Average score (-4.323529411764706)\n",
            "Win/lose count 11.5/18.0. Average score (-4.444444444444445)\n",
            "Win/lose count 11.5/18.0. Average score (-4.552631578947368)\n",
            "Win/lose count 7.0/7.0. Average score (-4.325)\n",
            "Win/lose count 9.0/11.0. Average score (-4.214285714285714)\n",
            "Win/lose count 11.5/13.0. Average score (-4.090909090909091)\n",
            "Win/lose count 11.5/17.0. Average score (-4.1521739130434785)\n",
            "Win/lose count 6.5/14.0. Average score (-4.291666666666667)\n",
            "Win/lose count 11.0/19.0. Average score (-4.44)\n",
            "Win/lose count 12.0/15.0. Average score (-4.384615384615385)\n",
            "Win/lose count 9.0/14.0. Average score (-4.407407407407407)\n",
            "Win/lose count 12.5/13.0. Average score (-4.267857142857143)\n",
            "Win/lose count 10.5/26.0. Average score (-4.655172413793103)\n",
            "Win/lose count 9.0/7.0. Average score (-4.433333333333334)\n",
            "Win/lose count 8.0/14.0. Average score (-4.483870967741935)\n",
            "Final score: -4.483870967741935\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "0wuTpGAySu-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "## DQN"
      ]
    },
    {
      "metadata": {
        "id": "Y3IOEzusSu-m",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Let us assume here that $T=\\infty$.\n",
        "\n",
        "***\n",
        "__Question 5__ Let $\\pi$ be a policy, show that:\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{\\pi}(s,a)=E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{equation*}\n",
        "\n",
        "Then, show that for the optimal policy $\\pi^*$ (we assume its existence), the following holds: \n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "Finally, deduce that a plausible objective is:\n",
        "\n",
        "\\begin{equation*}\n",
        "\\mathcal{L}(\\theta)=E_{s' \\sim \\pi^*(.|s,a)}\\Vert r+\\gamma\\max_{a'}Q(s',a',\\theta)-Q(s,a,\\theta)\\Vert^{2}.\n",
        "\\end{equation*}\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "cYLd8eNHSu-n",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**proof**\n",
        "\n",
        "From the course we have : \n",
        "\\begin{align}\n",
        "Q^{\\pi}(s,a) = E[\\sum\\limits_{k=0}^\\infty \\gamma^k r_{t+k}|s_t=s,a_t=a ] \\\\\n",
        "Q^{\\pi}(s,a) = E[r(s,a) + \\sum\\limits_{k=1}^\\infty \\gamma^k r_{t+k}|s_t=s,a_t=a] \\\\\n",
        "Q^{\\pi}(s,a) = r(s,a) + \\gamma E[E[\\sum_{k=0}^{\\infty}[\\gamma^k r_{t+1+k}|s_{t+1}=s',a_{t+1}=a']|s_t = s, a_t = a] \\\\\n",
        "Q^{\\pi}(s,a)  =  r(s,a) + \\gamma \\sum_{(s',a')}(p(s_{t+1}=s',a_{t+1}=a' |s_t = s, a_t = a )[E[\\sum_{k=0}^{\\infty}\\gamma^k r_{t+1+k}|s_{t+1}=s',a_{t+1}=a']\\\\\n",
        "Q^{\\pi}(s,a) = E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\n",
        "\\end{align}\n",
        "\n",
        "Then we maximise this quantity: \n",
        "\n",
        "\\begin{align}\n",
        "Q^{\\ast}(s,a) =  \\max\\limits_{\\pi} Q^{\\pi}(s,a) \\\\\n",
        "Q^{\\ast}(s,a) = \\max\\limits_{\\pi} E_{(s',a')\\sim p(.|s,a)}[r(s,a)+\\gamma Q^{\\pi}(s',a')]\\\\\n",
        "Q^{\\ast}(s,a) = r(s,a)+ \\gamma\\max\\limits_{\\pi} E_{(s',a')\\sim p(.|s,a)}[Q^{\\pi}(s',a')]\\\\\n",
        "\\end{align}\n",
        "\n",
        "We have to show that we can switch the $\\max$ and $\\sum$ operations :\n",
        "\n",
        "\n",
        "\\begin{align}\n",
        " \\sum_{s'} p(s_{t+1}=s'|s_t = s, a_t = a ) \\max_{\\pi'}Q^{\\pi'}(s',a') = \\sum_{(s')} p(s_{t+1}=s' |s_t = s, a_t = a ) Q^{\\pi^\\ast (s',a')}(s',a') \\\\\n",
        "  \\sum_{s'} p(s_{t+1}=s'|s_t = s, a_t = a ) \\max_{\\pi'}Q^{\\pi'}(s',a') \\leq \\max_{\\pi'} \\sum_{s'} p(s_{t+1}=s' |s_t = s, a_t = a )Q^{\\pi'}(s',a') \n",
        "\\end{align}\n",
        "\n",
        "With $\\pi^\\ast$ the best policy.\n",
        "\n",
        "The other inequality is tivial (the maximum of a sum $\\leq$ sum of the maximum).\n",
        "\n",
        "We then have : \n",
        "\n",
        "\n",
        "\\begin{equation*}\n",
        "Q^{*}(s,a)=E_{s'\\sim \\pi^*(.|s,a)}[r(s,a)+\\gamma\\max_{a'}Q^{*}(s',a')].\n",
        "\\end{equation*}\n",
        "\n",
        "\n",
        "The proposed objective functions forces the network to found a solution that verifies the Bellman equation.\n"
      ]
    },
    {
      "metadata": {
        "id": "HSbKvEywSu-o",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The DQN-learning algorithm relies on these derivations to train the parameters $\\theta$ of a Deep Neural Network:\n",
        "\n",
        "1. At the state $s_t$, select the action $a_t$ with best reward using $Q_t$ and store the results;\n",
        "\n",
        "2. Obtain the new state $s_{t+1}$ from the environment $p$;\n",
        "\n",
        "3. Store $(s_t,a_t,s_{t+1})$;\n",
        "\n",
        "4. Obtain $Q_{t+1}$ by minimizing  $\\mathcal{L}$ from a recovered batch from the previously stored results.\n",
        "\n",
        "***\n",
        "__Question 6__ Implement the class ```Memory``` that stores moves (in a replay buffer) via ```remember``` and provides a ```random_access``` to these. Specify a maximum memory size to avoid side effects. You can for example use a ```list()``` and set by default ```max_memory=100```."
      ]
    },
    {
      "metadata": {
        "id": "MS-kCoPtSu-p",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Memory(object):\n",
        "    def __init__(self, max_memory=100):\n",
        "        self.max_memory = max_memory\n",
        "        self.memory = list()\n",
        "\n",
        "    def remember(self, m):\n",
        "        self.memory.append(m)\n",
        "        if len(self.memory) > self.max_memory:\n",
        "            self.memory = self.memory[1:]\n",
        "\n",
        "    def random_access(self):\n",
        "        return self.memory[np.random.randint(0,len(self.memory),1)[0]]\n",
        "         "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nGAzb9TgSu-s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "The pipeline we will use for training is given below:"
      ]
    },
    {
      "metadata": {
        "id": "Uqi1vJVkSu-u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train(agent,env,epoch,prefix=''):\n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "B5y9J6y4Su-w",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "__Question 7__ Implement the DQN training algorithm using a cascade of fully connected layers. You can use different learning rate, batch size or memory size parameters. In particular, the loss might oscillate while the player will start to win the games. You have to find a good criterium."
      ]
    },
    {
      "metadata": {
        "id": "PsoM_NBxSu-y",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN(Agent):\n",
        "    def __init__(self, grid_size,  epsilon = 0.1, memory_size=100, batch_size = 16,n_state=2):\n",
        "        super(DQN, self).__init__(epsilon = epsilon)\n",
        "\n",
        "        # Discount for Q learning\n",
        "        self.discount = 0.99\n",
        "        \n",
        "        self.grid_size = grid_size\n",
        "        \n",
        "        # number of state\n",
        "        self.n_state = n_state\n",
        "\n",
        "        # Memory\n",
        "        self.memory = Memory(memory_size)\n",
        "        \n",
        "        # Batch size when learning\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def learned_act(self, s):\n",
        "        return np.argmax(self.model.predict(s.reshape([1,s.shape[0],s.shape[1],s.shape[2]]))[0,:])\n",
        "\n",
        "    def reinforce(self, s_, n_s_, a_, r_, game_over_):\n",
        "        # Two steps: first memorize the states, second learn from the pool\n",
        "\n",
        "        self.memory.remember([s_, n_s_, a_, r_, game_over_])\n",
        "        input_states = np.zeros((self.batch_size, 5,5,self.n_state))\n",
        "        target_q = np.zeros((self.batch_size, 4))\n",
        "        for i in range(self.batch_size):\n",
        "            ######## FILL IN\n",
        "            s_i, n_s_i, a_i, r_i, game_over_i  = self.memory.random_access()\n",
        "            target_q[i] =self.model.predict(s_i.reshape([1,s_i.shape[0],s_i.shape[1],s_i.shape[2]]))[0]\n",
        "            input_states[i] = s_i\n",
        "            if game_over_i:\n",
        "                ######## FILL IN\n",
        "                target_q[i,a_] = r_i\n",
        "            else:\n",
        "                ######## FILL IN\n",
        "                #target_q[i,a_] = r_  + self.discount*max(self.model.predict(n_s_.reshape((1,s_.shape[0],s_.shape[1],s_.shape[2]))[0]))\n",
        "                target_q[i,a_] = r_i  + self.discount*max(self.model.predict(np.expand_dims(s_i, axis=0))[0])\n",
        "                \n",
        "        ######## FILL IN\n",
        "        # HINT: Clip the target to avoid exploiding gradients.. -- clipping is a bit tighter\n",
        "        target_q = np.clip(target_q, -3, 3)\n",
        "\n",
        "        l = self.model.train_on_batch(input_states, target_q)\n",
        "\n",
        "\n",
        "        return l\n",
        "    \n",
        "\n",
        "    def save(self,name_weights='model.h5',name_model='model.json'):\n",
        "        self.model.save_weights(name_weights, overwrite=True)\n",
        "        with open(name_model, \"w\") as outfile:\n",
        "            json.dump(self.model.to_json(), outfile)\n",
        "            \n",
        "    def load(self,name_weights='model.h5',name_model='model.json'):\n",
        "        with open(name_model, \"r\") as jfile:\n",
        "            model = model_from_json(json.load(jfile))\n",
        "        model.load_weights(name_weights)\n",
        "        model.compile(\"sgd\", \"mse\")\n",
        "        self.model = model\n",
        "\n",
        "            \n",
        "class DQN_FC(DQN):\n",
        "    def __init__(self, *args, lr=0.1,**kwargs):\n",
        "        super(DQN_FC, self).__init__( *args,**kwargs)\n",
        "        \n",
        "        # NN Model\n",
        "        \n",
        "        ####### FILL IN\n",
        "        model = Sequential()\n",
        "        #model.add(Flatten(input_shape=(5,5,self.n_state)))\n",
        "        model.add(Reshape((50,), input_shape=(5,5,self.n_state)))\n",
        "        model.add(Dense(30,activation ='relu')) \n",
        "        model.add(Dense(4))\n",
        "        \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D_n9tuWFdBXt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "42MUknOnSu-1",
        "colab_type": "code",
        "outputId": "d9d4dd36-e678-4162-9e6c-c501e39a0f76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_FC(size, lr=0.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent, env, epochs_train, prefix='fc_train')\n",
        "HTML(display_videos('fc_train50.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/010 | Loss 0.0006 | Win/lose count 4.5/1.0 (3.5)\n",
            "Epoch 001/010 | Loss 0.0198 | Win/lose count 2.5/7.0 (-4.5)\n",
            "Epoch 002/010 | Loss 0.0038 | Win/lose count 0.5/3.0 (-2.5)\n",
            "Epoch 003/010 | Loss 0.0090 | Win/lose count 1.0/1.0 (0.0)\n",
            "Epoch 004/010 | Loss 0.0484 | Win/lose count 4.0/6.0 (-2.0)\n",
            "Epoch 005/010 | Loss 0.0015 | Win/lose count 1.0/3.0 (-2.0)\n",
            "Epoch 006/010 | Loss 0.0055 | Win/lose count 4.0/7.0 (-3.0)\n",
            "Epoch 007/010 | Loss 0.0220 | Win/lose count 1.5/3.0 (-1.5)\n",
            "Epoch 008/010 | Loss 0.0741 | Win/lose count 6.0/3.0 (3.0)\n",
            "Epoch 009/010 | Loss 0.0126 | Win/lose count 6.0/8.0 (-2.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "metadata": {
        "id": "3LiHgxn3Su-4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 8__ Implement the DQN training algorithm using a CNN (for example, 2 convolutional layers and one final fully connected layer)."
      ]
    },
    {
      "metadata": {
        "id": "JXKnoAsVSu-5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class DQN_CNN(DQN):\n",
        "    def __init__(self, *args,lr=0.1,**kwargs):\n",
        "        super(DQN_CNN, self).__init__(*args,**kwargs)\n",
        "        \n",
        "        ###### FILL IN\n",
        "        model = Sequential()\n",
        "        model.add(Conv2D(5,(3,3), padding='valid'))\n",
        "        model.add(Conv2D(25,(3,3), padding='valid'))\n",
        "        model.add(Flatten())\n",
        "        model.add(Dense(4)) \n",
        "        model.compile(sgd(lr=lr, decay=1e-4, momentum=0.0), \"mse\")\n",
        "        self.model = model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O1pcWLntSu-9",
        "colab_type": "code",
        "outputId": "54482f25-b156-4e5e-82b8-826a2e42318d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "train(agent,env,epochs_train,prefix='cnn_train')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/010 | Loss 0.0381 | Win/lose count 3.5/3.0 (0.5)\n",
            "Epoch 001/010 | Loss 0.0068 | Win/lose count 2.5/7.0 (-4.5)\n",
            "Epoch 002/010 | Loss 0.0185 | Win/lose count 2.0/4.0 (-2.0)\n",
            "Epoch 003/010 | Loss 0.0047 | Win/lose count 9.5/8.0 (1.5)\n",
            "Epoch 004/010 | Loss 0.0111 | Win/lose count 8.5/9.0 (-0.5)\n",
            "Epoch 005/010 | Loss 0.0146 | Win/lose count 4.0/10.0 (-6.0)\n",
            "Epoch 006/010 | Loss 0.0026 | Win/lose count 5.0/8.0 (-3.0)\n",
            "Epoch 007/010 | Loss 0.0071 | Win/lose count 7.5/11.0 (-3.5)\n",
            "Epoch 008/010 | Loss 0.0102 | Win/lose count 8.0/11.0 (-3.0)\n",
            "Epoch 009/010 | Loss 0.0230 | Win/lose count 4.5/4.0 (0.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "epEAhyCOSu_A",
        "colab_type": "code",
        "outputId": "37c1d913-794f-4a9a-e972-c2f0202385e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "HTML(display_videos('cnn_train50.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "metadata": {
        "id": "Vg9oljk_Su_D",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__Question 9__ Test both algorithms and compare their performances. Which issue(s) do you observe? Observe also different behaviors by changing the temperature."
      ]
    },
    {
      "metadata": {
        "id": "zE8vPk2wSu_E",
        "colab_type": "code",
        "outputId": "50646f25-bc95-4a62-8be0-cfe9b4180d74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1139
        }
      },
      "cell_type": "code",
      "source": [
        "env = Environment(grid_size=size, max_time=T,temperature=0.3)\n",
        "agent_cnn = DQN_CNN(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_cnn.load(name_weights='cnn_trainmodel.h5',name_model='cnn_trainmodel.json')\n",
        "\n",
        "agent_fc = DQN_FC(size, lr=.1, epsilon = 0.1, memory_size=2000, batch_size = 32)\n",
        "agent_fc.load(name_weights='fc_trainmodel.h5',name_model='fc_trainmodel.json')\n",
        "print('Test of the CNN')\n",
        "test(agent_cnn,env,epochs_test,prefix='cnn_test')\n",
        "print('Test of the FC')\n",
        "test(agent_fc,env,epochs_test,prefix='fc_test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test of the CNN\n",
            "Win/lose count 1.5/2.0. Average score (-0.5)\n",
            "Win/lose count 2.5/1.0. Average score (0.5)\n",
            "Win/lose count 0/1.0. Average score (0.0)\n",
            "Win/lose count 0/1.0. Average score (-0.25)\n",
            "Win/lose count 1.0/0. Average score (0.0)\n",
            "Win/lose count 0/0. Average score (0.0)\n",
            "Win/lose count 0.5/0. Average score (0.07142857142857142)\n",
            "Win/lose count 1.5/1.0. Average score (0.125)\n",
            "Win/lose count 0.5/2.0. Average score (-0.05555555555555555)\n",
            "Win/lose count 0/1.0. Average score (-0.15)\n",
            "Win/lose count 0/0. Average score (-0.13636363636363635)\n",
            "Win/lose count 2.0/2.0. Average score (-0.125)\n",
            "Win/lose count 1.0/1.0. Average score (-0.11538461538461539)\n",
            "Win/lose count 0/2.0. Average score (-0.25)\n",
            "Win/lose count 2.0/1.0. Average score (-0.16666666666666666)\n",
            "Win/lose count 1.5/0. Average score (-0.0625)\n",
            "Win/lose count 2.0/0. Average score (0.058823529411764705)\n",
            "Win/lose count 0/0. Average score (0.05555555555555555)\n",
            "Win/lose count 0.5/0. Average score (0.07894736842105263)\n",
            "Win/lose count 0/0. Average score (0.075)\n",
            "Win/lose count 2.0/2.0. Average score (0.07142857142857142)\n",
            "Win/lose count 0.5/2.0. Average score (0.0)\n",
            "Win/lose count 0/0. Average score (0.0)\n",
            "Win/lose count 0.5/0. Average score (0.020833333333333332)\n",
            "Win/lose count 0.5/0. Average score (0.04)\n",
            "Win/lose count 0/0. Average score (0.038461538461538464)\n",
            "Win/lose count 0.5/1.0. Average score (0.018518518518518517)\n",
            "Win/lose count 0.5/0. Average score (0.03571428571428571)\n",
            "Win/lose count 0.5/0. Average score (0.05172413793103448)\n",
            "Win/lose count 0/0. Average score (0.05)\n",
            "Win/lose count 3.0/1.0. Average score (0.11290322580645161)\n",
            "Final score: 0.11290322580645161\n",
            "Test of the FC\n",
            "Win/lose count 2.0/0. Average score (2.0)\n",
            "Win/lose count 1.0/0. Average score (1.5)\n",
            "Win/lose count 0.5/0. Average score (1.1666666666666667)\n",
            "Win/lose count 0/0. Average score (0.875)\n",
            "Win/lose count 0.5/0. Average score (0.8)\n",
            "Win/lose count 2.0/2.0. Average score (0.6666666666666666)\n",
            "Win/lose count 1.0/0. Average score (0.7142857142857143)\n",
            "Win/lose count 4.0/6.0. Average score (0.375)\n",
            "Win/lose count 2.0/3.0. Average score (0.2222222222222222)\n",
            "Win/lose count 1.5/1.0. Average score (0.25)\n",
            "Win/lose count 0.5/2.0. Average score (0.09090909090909091)\n",
            "Win/lose count 0/0. Average score (0.08333333333333333)\n",
            "Win/lose count 1.5/2.0. Average score (0.038461538461538464)\n",
            "Win/lose count 0.5/1.0. Average score (0.0)\n",
            "Win/lose count 0.5/0. Average score (0.03333333333333333)\n",
            "Win/lose count 0.5/2.0. Average score (-0.0625)\n",
            "Win/lose count 0/0. Average score (-0.058823529411764705)\n",
            "Win/lose count 1.0/5.0. Average score (-0.2777777777777778)\n",
            "Win/lose count 0.5/0. Average score (-0.23684210526315788)\n",
            "Win/lose count 0.5/2.0. Average score (-0.3)\n",
            "Win/lose count 0/0. Average score (-0.2857142857142857)\n",
            "Win/lose count 0.5/1.0. Average score (-0.29545454545454547)\n",
            "Win/lose count 0.5/0. Average score (-0.2608695652173913)\n",
            "Win/lose count 0/0. Average score (-0.25)\n",
            "Win/lose count 1.0/1.0. Average score (-0.24)\n",
            "Win/lose count 0/4.0. Average score (-0.38461538461538464)\n",
            "Win/lose count 0.5/2.0. Average score (-0.42592592592592593)\n",
            "Win/lose count 0/1.0. Average score (-0.44642857142857145)\n",
            "Win/lose count 1.5/1.0. Average score (-0.41379310344827586)\n",
            "Win/lose count 1.0/1.0. Average score (-0.4)\n",
            "Win/lose count 0.5/0. Average score (-0.3709677419354839)\n",
            "Final score: -0.3709677419354839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-2Jm1IVxSu_I",
        "colab_type": "code",
        "outputId": "32555d46-5c33-4b56-d7b1-28012b2f4073",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('cnn_test9.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "metadata": {
        "id": "F7nB1AI0Su_L",
        "colab_type": "code",
        "outputId": "8aa3b15f-0030-4fc3-ef8d-de84e4732faa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 293
        }
      },
      "cell_type": "code",
      "source": [
        "HTML(display_videos('fc_test9.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "metadata": {
        "id": "1fNArypaSu_R",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Based on the tests I made, CNN with 2 convolutionnal layers seems to perform best on this task.\n",
        "\n",
        "As the temperature increases, both models perform better, but the CNN score growth is faster than the one of the fully connected layer.\n",
        "One issue of the models trains is that it will stop increasing in performance because it would rather go on empty spots than try to eat something that might be poisoned and got a poor score. "
      ]
    },
    {
      "metadata": {
        "id": "SIH8SQFdSu_S",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "\n",
        "The algorithm tends to not explore the map which can be an issue. We propose two ideas in order to encourage exploration:\n",
        "1. Incorporating a decreasing $\\epsilon$-greedy exploration. You can use the method ```set_epsilon```\n",
        "2. Append via the environment a new state that describes if a cell has been visited or not\n",
        "\n",
        "***\n",
        "__Question 10__ Design a new ```train_explore``` function and environment class ```EnvironmentExploring``` to tackle the issue of exploration.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "L6NGngpBSu_T",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "## use those samples of code:\n",
        "#In train explore:\n",
        "#state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "## In Environment exploring:\n",
        "# You will have to change n_state to 3 because you will use one more layer!\n",
        "#reward = 0\n",
        "#if train:\n",
        "#    reward = -self.malus_position[self.x, self.y]\n",
        "#self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "#reward = reward + self.board[self.x, self.y]\n",
        "# 3 \"feature\" states instead of 2\n",
        "#state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "#                                self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "#                        self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "\n",
        "def train_explore(agent,env,epoch,decay_parameter_epsilon=0.3,prefix=''):\n",
        "    #New training procedure that tries to improve the exploration of the algorithm\n",
        "    #decay_parameter_epsilon in order to use the decreasing $\\epsilon$-greedy exploration\n",
        "    \n",
        "    \n",
        "    # Number of won games\n",
        "    score = 0\n",
        "    loss = 0\n",
        "\n",
        "    for e in range(epoch):\n",
        "        # At each epoch, we restart to a fresh game and get the initial state\n",
        "        state = env.reset()\n",
        "        # This assumes that the games will terminate\n",
        "        game_over = False\n",
        "\n",
        "        win = 0\n",
        "        lose = 0\n",
        "        agent.set_epsilon(agent.epsilon*(1-decay_parameter_epsilon))\n",
        "        while not game_over:\n",
        "            # The agent performs an action\n",
        "            action = agent.act(state)\n",
        "\n",
        "            # Apply an action to the environment, get the next state, the reward\n",
        "            # and if the games end\n",
        "            prev_state = state\n",
        "            state, reward, game_over = env.act(action, train=True)\n",
        "\n",
        "            # Update the counters\n",
        "            if reward > 0:\n",
        "                win = win + reward\n",
        "            if reward < 0:\n",
        "                lose = lose -reward\n",
        "\n",
        "            # Apply the reinforcement strategy\n",
        "            loss = agent.reinforce(prev_state, state,  action, reward, game_over)\n",
        "\n",
        "        # Save as a mp4\n",
        "        if e % 10 == 0:\n",
        "            env.draw(prefix+str(e))\n",
        "\n",
        "        # Update stats\n",
        "        score += win-lose\n",
        "\n",
        "        print(\"Epoch {:03d}/{:03d} | Loss {:.4f} | Win/lose count {}/{} ({})\"\n",
        "              .format(e, epoch, loss, win, lose, win-lose))\n",
        "        agent.save(name_weights=prefix+'model.h5',name_model=prefix+'model.json')\n",
        "        \n",
        "class EnvironmentExploring(object):\n",
        "    def __init__(self, grid_size=10, max_time=500, temperature=0.1):\n",
        "        grid_size = grid_size+4\n",
        "        self.grid_size = grid_size\n",
        "        self.max_time = max_time\n",
        "        self.temperature = temperature\n",
        "\n",
        "        #board on which one plays\n",
        "        self.board = np.zeros((grid_size,grid_size))\n",
        "        self.position = np.zeros((grid_size,grid_size))\n",
        "        self.malus_position = np.zeros((grid_size,grid_size)) \n",
        "        # coordinate of the cat\n",
        "        self.x = 0\n",
        "        self.y = 1\n",
        "\n",
        "        # self time\n",
        "        self.t = 0\n",
        "\n",
        "        self.scale=16\n",
        "\n",
        "        self.to_draw = np.zeros((max_time+2, grid_size*self.scale, grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "    def draw(self,e):\n",
        "        skvideo.io.vwrite(str(e) + '.mp4', self.to_draw)\n",
        "\n",
        "    def get_frame(self,t):\n",
        "        b = np.zeros((self.grid_size,self.grid_size,3))+128\n",
        "        b[self.board>0,0] = 256\n",
        "        b[self.board < 0, 2] = 256\n",
        "        b[self.x,self.y,:]=256\n",
        "        b[-2:,:,:]=0\n",
        "        b[:,-2:,:]=0\n",
        "        b[:2,:,:]=0\n",
        "        b[:,:2,:]=0\n",
        "        \n",
        "        b =  cv2.resize(b, None, fx=self.scale, fy=self.scale, interpolation=cv2.INTER_NEAREST)\n",
        "\n",
        "        self.to_draw[t,:,:,:]=b\n",
        "\n",
        "\n",
        "    def act(self, action,train=False):\n",
        "        \"\"\"This function returns the new state, reward and decides if the\n",
        "        game ends.\"\"\"\n",
        "        #During the training phase going back to a position where the rat have already been before tends to decrease the \n",
        "        #total reward hence there is this train parameter that we have added (it tries to enforce the exploration)\n",
        "\n",
        "        self.get_frame(int(self.t))\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:, -2:] = -1\n",
        "\n",
        "        self.position[self.x, self.y] = 1\n",
        "        if action == 0:\n",
        "            if self.x == self.grid_size-3:\n",
        "                self.x = self.x-1\n",
        "            else:\n",
        "                self.x = self.x + 1\n",
        "        elif action == 1:\n",
        "            if self.x == 2:\n",
        "                self.x = self.x+1\n",
        "            else:\n",
        "                self.x = self.x-1\n",
        "        elif action == 2:\n",
        "            if self.y == self.grid_size - 3:\n",
        "                self.y = self.y - 1\n",
        "            else:\n",
        "                self.y = self.y + 1\n",
        "        elif action == 3:\n",
        "            if self.y == 2:\n",
        "                self.y = self.y + 1\n",
        "            else:\n",
        "                self.y = self.y - 1\n",
        "        else:\n",
        "            RuntimeError('Error: action not recognized')\n",
        "\n",
        "        self.t = self.t + 1     \n",
        "        \n",
        "        ## In Environment exploring:\n",
        "        # You will have to change n_state to 3 because you will use one more layer!\n",
        "        reward = 0\n",
        "        if train:\n",
        "            reward = -self.malus_position[self.x, self.y]\n",
        "        self.malus_position[self.x, self.y] = 0.1\n",
        "\n",
        "        reward = reward + self.board[self.x, self.y]\n",
        "        self.board[self.x, self.y] = 0\n",
        "        game_over = self.t > self.max_time\n",
        "        # 3 \"feature\" states instead of 2\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "        state = state[self.x-2:self.x+3,self.y-2:self.y+3,:]\n",
        "\n",
        "        return state, reward, game_over\n",
        "\n",
        "    def reset(self):\n",
        "        \"\"\"This function resets the game and returns the initial state\"\"\"\n",
        "\n",
        "        self.x = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "        self.y = np.random.randint(3, self.grid_size-3, size=1)[0]\n",
        "\n",
        "\n",
        "        bonus = 0.5*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        bonus = bonus.reshape(self.grid_size,self.grid_size)\n",
        "\n",
        "        malus = -1.0*np.random.binomial(1,self.temperature,size=self.grid_size**2)\n",
        "        malus = malus.reshape(self.grid_size, self.grid_size)\n",
        "\n",
        "        self.to_draw = np.zeros((self.max_time+2, self.grid_size*self.scale, self.grid_size*self.scale, 3))\n",
        "\n",
        "\n",
        "        malus[bonus>0]=0\n",
        "\n",
        "        self.board = bonus + malus\n",
        "\n",
        "        self.position = np.zeros((self.grid_size, self.grid_size))\n",
        "        self.position[0:2,:]= -1\n",
        "        self.position[:,0:2] = -1\n",
        "        self.position[-2:, :] = -1\n",
        "        self.position[:,-2:] = -1\n",
        "        self.board[self.x,self.y] = 0\n",
        "        self.t = 0\n",
        "\n",
        "        self.malus_position = np.zeros((self.grid_size, self.grid_size))\n",
        "        #At the begining the malus_position array must be setted to zero\n",
        "        state = np.concatenate((self.malus_position.reshape(self.grid_size, self.grid_size,1),\n",
        "                                        self.board.reshape(self.grid_size, self.grid_size,1),\n",
        "                                self.position.reshape(self.grid_size, self.grid_size,1)),axis=2)\n",
        "\n",
        "        state = state[self.x - 2:self.x + 3, self.y - 2:self.y + 3, :]\n",
        "        return state\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xFSOGQWDSu_W",
        "colab_type": "code",
        "outputId": "b1658595-1f50-4861-a490-d3964aba8ed3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1670
        }
      },
      "cell_type": "code",
      "source": [
        "# Training\n",
        "epochs_train=81\n",
        "env = EnvironmentExploring(grid_size=size, max_time=T, temperature=0.3)\n",
        "agent = DQN_CNN(size, lr=.1, epsilon = 1, memory_size=2000, batch_size = 32,n_state=3)\n",
        "train_explore(agent, env, epochs_train,decay_parameter_epsilon=0.1, prefix='cnn_train_explore')\n",
        "HTML(display_videos('cnn_train_explore80.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 000/081 | Loss 0.0180 | Win/lose count 8.5/22.90000000000003 (-14.40000000000003)\n",
            "Epoch 001/081 | Loss 0.0292 | Win/lose count 8.0/21.400000000000038 (-13.400000000000038)\n",
            "Epoch 002/081 | Loss 0.0234 | Win/lose count 6.0/26.400000000000084 (-20.400000000000084)\n",
            "Epoch 003/081 | Loss 0.0149 | Win/lose count 10.0/28.40000000000004 (-18.40000000000004)\n",
            "Epoch 004/081 | Loss 0.0168 | Win/lose count 11.5/38.20000000000012 (-26.700000000000117)\n",
            "Epoch 005/081 | Loss 0.0320 | Win/lose count 8.0/26.90000000000009 (-18.90000000000009)\n",
            "Epoch 006/081 | Loss 0.0318 | Win/lose count 9.0/28.800000000000097 (-19.800000000000097)\n",
            "Epoch 007/081 | Loss 0.0101 | Win/lose count 13.5/34.60000000000009 (-21.100000000000087)\n",
            "Epoch 008/081 | Loss 0.0175 | Win/lose count 6.0/22.300000000000054 (-16.300000000000054)\n",
            "Epoch 009/081 | Loss 0.0058 | Win/lose count 7.0/26.90000000000006 (-19.90000000000006)\n",
            "Epoch 010/081 | Loss 0.0250 | Win/lose count 7.5/29.000000000000085 (-21.500000000000085)\n",
            "Epoch 011/081 | Loss 0.0173 | Win/lose count 10.5/29.80000000000008 (-19.30000000000008)\n",
            "Epoch 012/081 | Loss 0.0262 | Win/lose count 6.0/31.500000000000085 (-25.500000000000085)\n",
            "Epoch 013/081 | Loss 0.0165 | Win/lose count 6.0/22.100000000000023 (-16.100000000000023)\n",
            "Epoch 014/081 | Loss 0.0034 | Win/lose count 1.5/22.29999999999999 (-20.79999999999999)\n",
            "Epoch 015/081 | Loss 0.0093 | Win/lose count 7.5/21.40000000000005 (-13.900000000000048)\n",
            "Epoch 016/081 | Loss 0.0084 | Win/lose count 8.0/29.600000000000087 (-21.600000000000087)\n",
            "Epoch 017/081 | Loss 0.0253 | Win/lose count 3.5/26.20000000000006 (-22.70000000000006)\n",
            "Epoch 018/081 | Loss 0.0218 | Win/lose count 8.5/27.400000000000045 (-18.900000000000045)\n",
            "Epoch 019/081 | Loss 0.0061 | Win/lose count 4.0/26.50000000000006 (-22.50000000000006)\n",
            "Epoch 020/081 | Loss 0.0111 | Win/lose count 5.5/23.200000000000035 (-17.700000000000035)\n",
            "Epoch 021/081 | Loss 0.0412 | Win/lose count 7.5/22.80000000000006 (-15.300000000000061)\n",
            "Epoch 022/081 | Loss 0.0113 | Win/lose count 7.0/31.100000000000048 (-24.100000000000048)\n",
            "Epoch 023/081 | Loss 0.0069 | Win/lose count 6.0/21.40000000000005 (-15.400000000000048)\n",
            "Epoch 024/081 | Loss 0.0079 | Win/lose count 3.5/23.90000000000005 (-20.40000000000005)\n",
            "Epoch 025/081 | Loss 0.0224 | Win/lose count 6.5/26.200000000000067 (-19.700000000000067)\n",
            "Epoch 026/081 | Loss 0.0504 | Win/lose count 10.0/28.000000000000064 (-18.000000000000064)\n",
            "Epoch 027/081 | Loss 0.0094 | Win/lose count 9.0/22.100000000000044 (-13.100000000000044)\n",
            "Epoch 028/081 | Loss 0.0061 | Win/lose count 8.0/26.400000000000055 (-18.400000000000055)\n",
            "Epoch 029/081 | Loss 0.0030 | Win/lose count 5.0/29.300000000000082 (-24.300000000000082)\n",
            "Epoch 030/081 | Loss 0.0073 | Win/lose count 7.0/21.40000000000005 (-14.400000000000048)\n",
            "Epoch 031/081 | Loss 0.0086 | Win/lose count 10.5/23.100000000000037 (-12.600000000000037)\n",
            "Epoch 032/081 | Loss 0.0055 | Win/lose count 10.0/21.00000000000002 (-11.000000000000021)\n",
            "Epoch 033/081 | Loss 0.0115 | Win/lose count 10.0/24.500000000000085 (-14.500000000000085)\n",
            "Epoch 034/081 | Loss 0.0051 | Win/lose count 8.0/28.800000000000143 (-20.800000000000143)\n",
            "Epoch 035/081 | Loss 0.0159 | Win/lose count 11.5/24.70000000000005 (-13.200000000000049)\n",
            "Epoch 036/081 | Loss 0.0092 | Win/lose count 7.0/24.50000000000007 (-17.50000000000007)\n",
            "Epoch 037/081 | Loss 0.0207 | Win/lose count 2.5/21.100000000000044 (-18.600000000000044)\n",
            "Epoch 038/081 | Loss 0.0105 | Win/lose count 6.0/23.500000000000046 (-17.500000000000046)\n",
            "Epoch 039/081 | Loss 0.0215 | Win/lose count 6.0/24.70000000000003 (-18.70000000000003)\n",
            "Epoch 040/081 | Loss 0.0308 | Win/lose count 10.5/25.600000000000026 (-15.100000000000026)\n",
            "Epoch 041/081 | Loss 0.0126 | Win/lose count 3.5/22.000000000000043 (-18.500000000000043)\n",
            "Epoch 042/081 | Loss 0.0055 | Win/lose count 8.0/22.80000000000007 (-14.800000000000072)\n",
            "Epoch 043/081 | Loss 0.0177 | Win/lose count 8.5/28.800000000000082 (-20.300000000000082)\n",
            "Epoch 044/081 | Loss 0.0123 | Win/lose count 9.0/24.600000000000087 (-15.600000000000087)\n",
            "Epoch 045/081 | Loss 0.0573 | Win/lose count 10.0/22.000000000000064 (-12.000000000000064)\n",
            "Epoch 046/081 | Loss 0.0065 | Win/lose count 4.0/20.70000000000003 (-16.70000000000003)\n",
            "Epoch 047/081 | Loss 0.0062 | Win/lose count 5.5/22.300000000000015 (-16.800000000000015)\n",
            "Epoch 048/081 | Loss 0.0055 | Win/lose count 9.0/29.800000000000047 (-20.800000000000047)\n",
            "Epoch 049/081 | Loss 0.0062 | Win/lose count 8.0/23.100000000000044 (-15.100000000000044)\n",
            "Epoch 050/081 | Loss 0.0127 | Win/lose count 11.5/29.20000000000005 (-17.70000000000005)\n",
            "Epoch 051/081 | Loss 0.0056 | Win/lose count 12.5/21.600000000000037 (-9.100000000000037)\n",
            "Epoch 052/081 | Loss 0.0167 | Win/lose count 2.0/27.400000000000095 (-25.400000000000095)\n",
            "Epoch 053/081 | Loss 0.0074 | Win/lose count 3.5/23.900000000000066 (-20.400000000000066)\n",
            "Epoch 054/081 | Loss 0.0148 | Win/lose count 8.0/21.099999999999998 (-13.099999999999998)\n",
            "Epoch 055/081 | Loss 0.0012 | Win/lose count 9.0/26.600000000000108 (-17.600000000000108)\n",
            "Epoch 056/081 | Loss 0.0158 | Win/lose count 3.5/26.9000000000001 (-23.4000000000001)\n",
            "Epoch 057/081 | Loss 0.0083 | Win/lose count 11.5/30.000000000000018 (-18.500000000000018)\n",
            "Epoch 058/081 | Loss 0.0163 | Win/lose count 6.0/30.800000000000104 (-24.800000000000104)\n",
            "Epoch 059/081 | Loss 0.0122 | Win/lose count 9.5/28.40000000000005 (-18.90000000000005)\n",
            "Epoch 060/081 | Loss 0.0329 | Win/lose count 10.5/24.20000000000005 (-13.700000000000049)\n",
            "Epoch 061/081 | Loss 0.0145 | Win/lose count 11.0/35.7000000000001 (-24.700000000000102)\n",
            "Epoch 062/081 | Loss 0.0176 | Win/lose count 6.0/25.6000000000001 (-19.6000000000001)\n",
            "Epoch 063/081 | Loss 0.0162 | Win/lose count 5.5/26.50000000000008 (-21.00000000000008)\n",
            "Epoch 064/081 | Loss 0.0186 | Win/lose count 9.5/24.60000000000005 (-15.100000000000051)\n",
            "Epoch 065/081 | Loss 0.0185 | Win/lose count 16.5/18.499999999999982 (-1.9999999999999822)\n",
            "Epoch 066/081 | Loss 0.0534 | Win/lose count 1.5/22.100000000000048 (-20.600000000000048)\n",
            "Epoch 067/081 | Loss 0.0449 | Win/lose count 10.5/26.400000000000098 (-15.900000000000098)\n",
            "Epoch 068/081 | Loss 0.0340 | Win/lose count 12.0/25.200000000000017 (-13.200000000000017)\n",
            "Epoch 069/081 | Loss 0.0194 | Win/lose count 5.5/28.600000000000087 (-23.100000000000087)\n",
            "Epoch 070/081 | Loss 0.0118 | Win/lose count 5.0/21.600000000000055 (-16.600000000000055)\n",
            "Epoch 071/081 | Loss 0.0155 | Win/lose count 7.5/26.5000000000001 (-19.0000000000001)\n",
            "Epoch 072/081 | Loss 0.0146 | Win/lose count 9.0/29.000000000000064 (-20.000000000000064)\n",
            "Epoch 073/081 | Loss 0.0446 | Win/lose count 6.0/28.10000000000004 (-22.10000000000004)\n",
            "Epoch 074/081 | Loss 0.0249 | Win/lose count 9.5/23.600000000000065 (-14.100000000000065)\n",
            "Epoch 075/081 | Loss 0.0190 | Win/lose count 8.0/30.500000000000103 (-22.500000000000103)\n",
            "Epoch 076/081 | Loss 0.0019 | Win/lose count 9.5/20.89999999999999 (-11.399999999999991)\n",
            "Epoch 077/081 | Loss 0.0226 | Win/lose count 6.5/22.80000000000007 (-16.30000000000007)\n",
            "Epoch 078/081 | Loss 0.0145 | Win/lose count 4.5/25.300000000000036 (-20.800000000000036)\n",
            "Epoch 079/081 | Loss 0.0175 | Win/lose count 11.5/27.400000000000084 (-15.900000000000084)\n",
            "Epoch 080/081 | Loss 0.0054 | Win/lose count 13.5/25.90000000000004 (-12.400000000000041)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "metadata": {
        "id": "TEkbQIHdSu_a",
        "colab_type": "code",
        "outputId": "3e0520ad-e5c6-4607-d310-de2058ef7844",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 837
        }
      },
      "cell_type": "code",
      "source": [
        " # Evaluation\n",
        "test(agent,env,epochs_test,prefix='cnn_test_explore')\n",
        "HTML(display_videos('cnn_test_explore30.mp4'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Win/lose count 0.5/1.0. Average score (-0.5)\n",
            "Win/lose count 0.5/1.0. Average score (-0.5)\n",
            "Win/lose count 0.5/0. Average score (-0.16666666666666666)\n",
            "Win/lose count 1.5/3.0. Average score (-0.5)\n",
            "Win/lose count 0/1.0. Average score (-0.6)\n",
            "Win/lose count 1.5/2.0. Average score (-0.5833333333333334)\n",
            "Win/lose count 0.5/1.0. Average score (-0.5714285714285714)\n",
            "Win/lose count 0.5/0. Average score (-0.4375)\n",
            "Win/lose count 1.5/0. Average score (-0.2222222222222222)\n",
            "Win/lose count 0/0. Average score (-0.2)\n",
            "Win/lose count 1.0/0. Average score (-0.09090909090909091)\n",
            "Win/lose count 1.5/0. Average score (0.041666666666666664)\n",
            "Win/lose count 0.5/2.0. Average score (-0.07692307692307693)\n",
            "Win/lose count 0/0. Average score (-0.07142857142857142)\n",
            "Win/lose count 0.5/3.0. Average score (-0.23333333333333334)\n",
            "Win/lose count 0.5/2.0. Average score (-0.3125)\n",
            "Win/lose count 4.0/2.0. Average score (-0.17647058823529413)\n",
            "Win/lose count 2.0/2.0. Average score (-0.16666666666666666)\n",
            "Win/lose count 1.5/2.0. Average score (-0.18421052631578946)\n",
            "Win/lose count 0.5/1.0. Average score (-0.2)\n",
            "Win/lose count 1.0/1.0. Average score (-0.19047619047619047)\n",
            "Win/lose count 0.5/1.0. Average score (-0.20454545454545456)\n",
            "Win/lose count 0.5/1.0. Average score (-0.21739130434782608)\n",
            "Win/lose count 0/0. Average score (-0.20833333333333334)\n",
            "Win/lose count 1.5/0. Average score (-0.14)\n",
            "Win/lose count 2.5/1.0. Average score (-0.07692307692307693)\n",
            "Win/lose count 1.0/2.0. Average score (-0.1111111111111111)\n",
            "Win/lose count 0/4.0. Average score (-0.25)\n",
            "Win/lose count 2.0/3.0. Average score (-0.27586206896551724)\n",
            "Win/lose count 0.5/1.0. Average score (-0.2833333333333333)\n",
            "Win/lose count 1.5/0. Average score (-0.22580645161290322)\n",
            "Final score: -0.22580645161290322\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<video alt=\"test\" controls>\n",
              "                <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\" />\n",
              "             </video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "metadata": {
        "id": "d4a1LC3DlrV0",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "The model seems to work better during the training set (based on the video). On the test part I can't see any improvement.\n",
        "I noticed that the number of win/loss game is always negative. I tried to investigate where this could came from in the code but I didn't found where is my bug."
      ]
    },
    {
      "metadata": {
        "id": "9YmTUdyMSu_d",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***\n",
        "***\n",
        "__BONUS question__ Use the expert DQN from the previous question to generate some winning games. Train a model that mimicks its behavior. Compare the performances."
      ]
    },
    {
      "metadata": {
        "id": "XuxsDVHLSu_e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        ""
      ]
    },
    {
      "metadata": {
        "id": "Aj-Ql7tiSu_e",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***"
      ]
    }
  ]
}